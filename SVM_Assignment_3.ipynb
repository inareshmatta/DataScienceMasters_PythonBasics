{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc42651",
   "metadata": {},
   "source": [
    "Q1. In order to predict house price based on several characteristics, such as location, square footage,\n",
    "number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this\n",
    "situation would be the best to employ? \n",
    "Dataset link:https://drive.google.com/file/d/1Z9oLpmt6IDRNw7IeNcHYTGeJRYypRSC0/view?usp=share_link \n",
    "\n",
    "Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as\n",
    "your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price\n",
    "of a house as accurately as possible?  \n",
    "Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate\n",
    "regression metric to use with your SVM model. Which metric would be the most appropriate in this\n",
    "scenario?  \n",
    "Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best\n",
    "metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values\n",
    "are very close. Which metric should you choose to use in this case?  \n",
    "Q5. You are comparing the performance of different SVM regression models using different kernels (linear,\n",
    "polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most\n",
    "appropriate if your goal is to measure how well the model explains the variance in the target variable?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67a35fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 45.932645142452536\n",
      "Mean Squared Error: 17011.14628137756\n",
      "Root Mean Squared Error: 130.42678513778358\n",
      "R-squared (R^2) Score: 0.20099970257632127\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Bengaluru_House_Data.csv')\n",
    "\n",
    "# Handle missing values\n",
    "# Impute missing values with median for numerical features and mode for categorical features\n",
    "numeric_features = ['bath', 'balcony']  # Numeric features list\n",
    "categorical_features = ['area_type', 'availability', 'location', 'size', 'total_sqft']  # Categorical features list\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = df.drop(columns=['price'])\n",
    "y = df['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the SVR model\n",
    "svr_model = SVR()\n",
    "\n",
    "# Create a pipeline with preprocessing and SVR model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', svr_model)])\n",
    "\n",
    "# Train the SVR regression model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using regression metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared (R^2) Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df605c",
   "metadata": {},
   "source": [
    "### Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price of a house as accurately as possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8c95f",
   "metadata": {},
   "source": [
    "If your goal is to predict the actual price of a house as accurately as possible, Mean Squared Error (MSE) would be a more appropriate evaluation metric for your SVM regression model.\n",
    "\n",
    "Here's why:\n",
    "\n",
    "1. **Interpretability**: MSE measures the average squared difference between the predicted and actual values. In the context of house prices, MSE directly reflects how much, on average, your predictions deviate from the true prices. This provides a clear and interpretable measure of the model's performance in terms of prediction accuracy.\n",
    "\n",
    "2. **Focus on Prediction Accuracy**: MSE penalizes larger errors more heavily due to the squaring of the differences. Minimizing MSE encourages the model to make more accurate predictions, which aligns with your goal of predicting house prices as accurately as possible.\n",
    "\n",
    "3. **Commonly Used Metric**: MSE is one of the most commonly used metrics for regression tasks. Its widespread usage makes it easier to compare your model's performance with other regression models or benchmarks.\n",
    "\n",
    "While R-squared (coefficient of determination) is another commonly used metric for regression models, it measures the proportion of the variance in the dependent variable that is predictable from the independent variables. While R-squared provides insights into how well the independent variables explain the variance in the dependent variable, it may not directly reflect prediction accuracy, which is crucial for your goal of predicting house prices accurately. Therefore, MSE would be more suitable for evaluating your SVM regression model in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4fe414",
   "metadata": {},
   "source": [
    "### Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate regression metric to use with your SVM model. Which metric would be the most appropriate in this scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27b716",
   "metadata": {},
   "source": [
    "When dealing with a dataset that contains a significant number of outliers, using a robust regression metric is crucial to ensure that the model's performance is not overly influenced by these outliers. In this scenario, the most appropriate regression metric to use with your SVM model would be Mean Absolute Error (MAE).\n",
    "\n",
    "Here's why MAE is suitable for handling outliers:\n",
    "\n",
    "1. **Robustness to Outliers**: MAE calculates the average absolute difference between the predicted and actual values. Unlike Mean Squared Error (MSE), which squares the differences and therefore heavily penalizes large errors, MAE treats all errors equally. This makes MAE more robust to outliers because it does not amplify the effect of extreme values on the overall metric.\n",
    "\n",
    "2. **Interpretability**: Similar to MSE, MAE provides a straightforward interpretation of prediction accuracy. It represents the average magnitude of errors in the predictions, making it easy to understand and communicate.\n",
    "\n",
    "3. **Less Sensitive to Extreme Values**: Since MAE does not square the errors, it is less sensitive to extreme values compared to MSE. This property makes MAE more suitable for datasets with a significant number of outliers, as it ensures that the model's performance is not disproportionately affected by these outliers.\n",
    "\n",
    "Overall, when dealing with a dataset containing outliers and aiming to select a regression metric for evaluating an SVM model, Mean Absolute Error (MAE) is the most appropriate choice due to its robustness to outliers and ease of interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b5b48",
   "metadata": {},
   "source": [
    "### Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values are very close. Which metric should you choose to use in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe4554",
   "metadata": {},
   "source": [
    "When both Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) values are very close, it indicates that the scale of the errors is consistent across the dataset. In such cases, choosing between MSE and RMSE depends on specific considerations related to the context and preferences of the analysis. Here are some factors to consider:\n",
    "\n",
    "1. **Interpretability**: MSE is directly interpretable as it represents the average squared difference between predicted and actual values. On the other hand, RMSE is more interpretable in the same units as the target variable, which can be advantageous when communicating the model's performance to stakeholders who might be more familiar with the original scale of the data.\n",
    "\n",
    "2. **Sensitivity to Large Errors**: RMSE penalizes large errors more than MSE because it involves taking the square root of the squared errors. If your primary concern is to ensure that large errors are appropriately accounted for in the evaluation, RMSE might be preferred.\n",
    "\n",
    "3. **Computational Efficiency**: MSE is computationally simpler to calculate compared to RMSE since it does not involve taking the square root. If computational efficiency is a concern, especially in scenarios involving large datasets or real-time applications, MSE might be preferred.\n",
    "\n",
    "4. **Consistency with Other Metrics**: Consider whether there are other evaluation metrics being used in the analysis and choose the metric that aligns well with the overall evaluation framework.\n",
    "\n",
    "Ultimately, if both MSE and RMSE are very close and there are no specific considerations favoring one over the other, either metric can be used interchangeably. It is essential to document the choice made and provide justification for it in the context of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204cec3b",
   "metadata": {},
   "source": [
    "### Q5. You are comparing the performance of different SVM regression models using different kernels (linear, polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382e0b9",
   "metadata": {},
   "source": [
    "When comparing the performance of different SVM regression models with different kernels (linear, polynomial, and RBF) and aiming to measure how well the model explains the variance in the target variable, the most appropriate evaluation metric is **R-squared (Coefficient of Determination)**.\n",
    "\n",
    "R-squared is a statistical measure that represents the proportion of the variance in the dependent variable (target variable) that is predictable from the independent variables (features) in the model. It ranges from 0 to 1, where:\n",
    "\n",
    "- R-squared = 1 indicates that the model explains all the variability of the target variable around its mean.\n",
    "- R-squared = 0 indicates that the model does not explain any variability of the target variable around its mean.\n",
    "\n",
    "Since the goal is to measure how well the model explains the variance in the target variable, R-squared is particularly suitable because it directly quantifies the goodness of fit of the regression model. Higher R-squared values indicate better model performance in terms of explaining the variance in the target variable.\n",
    "\n",
    "Therefore, when comparing SVM regression models with different kernels and aiming to select the best model based on its ability to explain the variance in the target variable, R-squared would be the most appropriate evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b4cc13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
