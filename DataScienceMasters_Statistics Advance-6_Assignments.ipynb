{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f052845d",
   "metadata": {},
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a46667",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means among different groups. There are several assumptions that need to be met for ANOVA to provide valid and reliable results. Here are the main assumptions of ANOVA along with examples of violations that could impact the validity of the results:\n",
    "\n",
    "### Assumptions of ANOVA:\n",
    "\n",
    "1. **Normality:**\n",
    "   - **Assumption:** The data within each group should be approximately normally distributed.\n",
    "   - **Example Violation:** If the data in one or more groups deviates significantly from normality, it may affect the results. This can be assessed using normality tests or visual inspection of histograms.\n",
    "\n",
    "2. **Homogeneity of Variances (Homoscedasticity):**\n",
    "   - **Assumption:** The variances of the groups being compared should be approximately equal.\n",
    "   - **Example Violation:** Unequal variances can lead to inflated Type I error rates or reduced power. Levene's test or Bartlett's test can be used to assess homogeneity of variances.\n",
    "\n",
    "3. **Independence:**\n",
    "   - **Assumption:** Observations within each group should be independent of each other.\n",
    "   - **Example Violation:** If observations within a group are correlated, it may lead to pseudoreplication and affect the accuracy of the results. Ensure independence through appropriate study design.\n",
    "\n",
    "4. **Random Sampling:**\n",
    "   - **Assumption:** Observations should be randomly and independently sampled from the populations being studied.\n",
    "   - **Example Violation:** If the sampling is biased or non-random, it may introduce selection bias and impact the generalizability of the results.\n",
    "\n",
    "### Examples of Violations:\n",
    "\n",
    "1. **Skewed Distributions:**\n",
    "   - **Violation:** If the distribution within a group is highly skewed, it may affect the normality assumption.\n",
    "   - **Impact:** ANOVA is robust to mild departures from normality, but extreme skewness might lead to inaccurate results.\n",
    "\n",
    "2. **Heterogeneous Variances:**\n",
    "   - **Violation:** Unequal variances among groups violate the assumption of homogeneity of variances.\n",
    "   - **Impact:** It can lead to incorrect conclusions about group differences, and adjustments or alternative methods may be needed.\n",
    "\n",
    "3. **Correlated Observations:**\n",
    "   - **Violation:** If observations within a group are not independent, it violates the independence assumption.\n",
    "   - **Impact:** It may lead to inflated Type I error rates or distorted confidence intervals.\n",
    "\n",
    "4. **Non-Random Sampling:**\n",
    "   - **Violation:** If the sampling process is not random, it violates the random sampling assumption.\n",
    "   - **Impact:** Results may not be generalizable to the larger population.\n",
    "\n",
    "### Dealing with Violations:\n",
    "\n",
    "1. **Transformations:**\n",
    "   - If normality is violated, applying transformations (e.g., log-transform) might help.\n",
    "\n",
    "2. **Non-parametric Tests:**\n",
    "   - When assumptions are seriously violated, non-parametric alternatives (e.g., Kruskal-Wallis test) can be considered.\n",
    "\n",
    "3. **Bootstrapping:**\n",
    "   - Bootstrapping techniques can be used to address violations of assumptions, especially when sample sizes are small.\n",
    "\n",
    "It's essential to check these assumptions before interpreting the results of an ANOVA analysis to ensure the validity and reliability of the findings. If assumptions are severely violated, alternative approaches may be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84aefd9",
   "metadata": {},
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74b257",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means among different groups. There are three main types of ANOVA, each suited for different situations:\n",
    "\n",
    "### 1. One-Way ANOVA:\n",
    "\n",
    "- **Situation:**\n",
    "  - Used when comparing means of three or more independent (unrelated) groups.\n",
    "  - There is one categorical independent variable (factor) with three or more levels (groups).\n",
    "  - Assumes that the populations being compared have the same variance.\n",
    "\n",
    "- **Example:**\n",
    "  - Comparing the mean scores of students in three different teaching methods (A, B, C) to determine if there is a significant difference in their exam performance.\n",
    "\n",
    "- **Formula:**\n",
    "  - $( F = \\frac{\\text{Between-group variability}}{\\text{Within-group variability}})$\n",
    "\n",
    "### 2. Two-Way ANOVA:\n",
    "\n",
    "- **Situation:**\n",
    "  - Used when comparing means of groups formed by two independent categorical variables (factors).\n",
    "  - There are two main effects and an interaction effect between the two factors.\n",
    "  - Can be used to explore the impact of each factor individually and their interaction.\n",
    "\n",
    "- **Example:**\n",
    "  - Investigating the influence of both gender and treatment type on the effectiveness of a drug.\n",
    "\n",
    "- **Formula:**\n",
    "  - $( F = \\frac{\\text{Between-group variability}}{\\text{Within-group variability}})$\n",
    "\n",
    "### 3. Repeated Measures ANOVA:\n",
    "\n",
    "- **Situation:**\n",
    "  - Used when comparing means of the same group across different time points or conditions.\n",
    "  - There is one group of participants measured under different conditions or at multiple time points.\n",
    "  - Assumes that the variances of the differences between all possible pairs of conditions are equal.\n",
    "\n",
    "- **Example:**\n",
    "  - Analyzing the effect of a training program by measuring participants' performance before, during, and after the training.\n",
    "\n",
    "- **Formula:**\n",
    "  - Similar to one-way ANOVA but considers the within-subject variability.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Between-Group Variability:**\n",
    "  - Represents the variation in means between different groups.\n",
    "\n",
    "- **Within-Group Variability:**\n",
    "  - Represents the variation within each group.\n",
    "\n",
    "- **F-Statistic:**\n",
    "  - The ratio of between-group variability to within-group variability. A high F-value suggests that the group means are significantly different.\n",
    "\n",
    "- **P-value:**\n",
    "  - Determines the statistical significance of the F-statistic. If the p-value is less than the chosen significance level, the null hypothesis is rejected.\n",
    "\n",
    "Choosing the appropriate type of ANOVA depends on the study design and the nature of the independent variables. One-way ANOVA is used for independent groups, two-way ANOVA for two independent variables, and repeated measures ANOVA for repeated measurements on the same group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee40c86",
   "metadata": {},
   "source": [
    "### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586af652",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) refers to the process of decomposing the total variability in the data into different components, each associated with specific sources. Understanding this partitioning is crucial for interpreting ANOVA results and gaining insights into the contributions of various factors to the overall variability in the data.\n",
    "\n",
    "### Components of Variance in ANOVA:\n",
    "\n",
    "1. **Total Variance $(SS_{\\text{Total}}))$:**\n",
    "   - Represents the total variability in the dependent variable across all observations.\n",
    "   - Computed as the sum of squared differences between each individual data point and the overall mean.\n",
    "\n",
    "   $[ SS_{\\text{Total}} = \\sum (Y_{ij} - \\bar{Y}_{\\text{Total}})^2 ]$\n",
    "\n",
    "2. **Between-Group Variance (\\(SS_{\\text{Between}})\\):**\n",
    "   - Represents the variability in the dependent variable that is attributable to differences between the group means.\n",
    "   - Computed as the sum of squared differences between each group mean and the overall mean, weighted by the number of observations in each group.\n",
    "\n",
    "   $[ SS_{\\text{Between}} = \\sum N_j (\\bar{Y}_j - \\bar{Y}_{\\text{Total}})^2 ]$\n",
    "\n",
    "3. **Within-Group Variance (\\(SS_{\\text{Within}})\\):**\n",
    "   - Represents the variability in the dependent variable that is not explained by differences between the group means.\n",
    "   - Computed as the sum of squared differences between each individual data point and its respective group mean.\n",
    "\n",
    "   $[ SS_{\\text{Within}} = \\sum \\sum (Y_{ij} - \\bar{Y}_j)^2 ]$\n",
    "\n",
    "### Relationship:\n",
    "\n",
    "The total variance can be decomposed into the sum of the between-group variance and the within-group variance:\n",
    "\n",
    "$[ SS_{\\text{Total}} = SS_{\\text{Between}} + SS_{\\text{Within}} ]$\n",
    "\n",
    "### Importance of Understanding Partitioning of Variance:\n",
    "\n",
    "1. **Identifying Sources of Variation:**\n",
    "   - Helps researchers understand the relative contributions of different factors or groups to the overall variability in the data.\n",
    "\n",
    "2. **ANOVA F-Statistic:**\n",
    "   - The ratio of between-group variance to within-group variance $(F = \\frac{MS_{\\text{Between}}}{MS_{\\text{Within}}})$ is used to assess the statistical significance of group differences. A high F-value indicates that the group means are significantly different.\n",
    "\n",
    "3. **Effect Size:**\n",
    "   - The proportion of total variance explained by the between-group variance provides an indication of the effect size, helping to evaluate the practical significance of the observed differences.\n",
    "\n",
    "4. **Post-hoc Analysis:**\n",
    "   - Understanding the partitioning of variance guides post-hoc analyses to explore specific group differences or interactions that contribute to the observed patterns.\n",
    "\n",
    "5. **Model Evaluation:**\n",
    "   - Helps in assessing the adequacy of the ANOVA model and whether the included factors adequately explain the observed variability.\n",
    "\n",
    "In summary, the partitioning of variance in ANOVA provides a comprehensive view of the distribution of variability in the data, facilitating a deeper understanding of group differences and the impact of various factors on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea416c82",
   "metadata": {},
   "source": [
    "### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a18960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 65.33333333333334\n",
      "Explained Sum of Squares (SSE): 54.33333333333335\n",
      "Residual Sum of Squares (SSR): 11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Assuming 'data' is your DataFrame with columns 'group' and 'value'\n",
    "# 'group' is the categorical variable (factor)\n",
    "# 'value' is the continuous variable (dependent variable)\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'value': [10, 12, 15, 18, 8, 11]\n",
    "})\n",
    "\n",
    "# Fit the one-way ANOVA model\n",
    "model = ols('value ~ group', data=data).fit()\n",
    "\n",
    "# Get ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract sums of squares from the ANOVA table\n",
    "SST = anova_table['sum_sq']['group'] + anova_table['sum_sq']['Residual']\n",
    "SSE = anova_table['sum_sq']['group']\n",
    "SSR = anova_table['sum_sq']['Residual']\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab8859",
   "metadata": {},
   "source": [
    "### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d6cdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor 1: 60.50000000000011\n",
      "Main Effect of Factor 2: 12.500000000000044\n",
      "Interaction Effect: 1.5777218104420236e-30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Assuming you have a DataFrame named 'data' with columns 'factor1', 'factor2', and 'value'\n",
    "# 'factor1' and 'factor2' are the two categorical variables (factors)\n",
    "# 'value' is the continuous variable (dependent variable)\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'factor1': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'B'],\n",
    "    'factor2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "    'value': [10, 12, 15, 18, 8, 11, 14, 16]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('value ~ factor1 * factor2', data=data).fit()\n",
    "\n",
    "# Get ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effects\n",
    "main_effect_factor1 = anova_table['sum_sq']['factor1']\n",
    "main_effect_factor2 = anova_table['sum_sq']['factor2']\n",
    "interaction_effect = anova_table['sum_sq']['factor1:factor2']\n",
    "\n",
    "print(\"Main Effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main Effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b668a",
   "metadata": {},
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0584a",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences between the means of three or more groups. The associated p-value helps determine the statistical significance of the observed differences. Here's how to interpret the results:\n",
    "\n",
    "1. **Null Hypothesis (H0):** The null hypothesis in ANOVA states that there are no significant differences between the group means.\n",
    "\n",
    "2. **Alternative Hypothesis (H1):** The alternative hypothesis suggests that at least one group mean is different from the others.\n",
    "\n",
    "Given your results:\n",
    "\n",
    "- **F-statistic of 5.23:** This is the test statistic that follows an F-distribution. It measures the ratio of the variance between groups to the variance within groups. A higher F-statistic indicates a larger difference between group means.\n",
    "\n",
    "- **p-value of 0.02:** This is the probability of observing an F-statistic as extreme as the one obtained if the null hypothesis were true. A p-value less than the chosen significance level (commonly 0.05) suggests that you reject the null hypothesis.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "Since the p-value (0.02) is less than the typical significance level of 0.05, you would reject the null hypothesis. This suggests that there is sufficient evidence to conclude that at least one group mean is different from the others.\n",
    "\n",
    "In practical terms, you can interpret this as follows:\n",
    "\n",
    "\"There are statistically significant differences between the group means. The data provide enough evidence to reject the null hypothesis, indicating that there are meaningful variations in the dependent variable across the groups.\"\n",
    "\n",
    "Keep in mind that to identify which specific groups are different, you may need to perform post-hoc tests (e.g., Tukey's HSD test) or pairwise comparisons. The significant F-statistic indicates overall group differences, but additional tests are required for detailed comparisons between individual groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c2045",
   "metadata": {},
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f24f43",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is an important aspect of data analysis. Different methods can be used, and the choice of method can impact the results. Here are some common approaches to handling missing data in repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "1. **Complete Case Analysis (CCA):**\n",
    "   - **Method:** Exclude cases with missing data.\n",
    "   - **Consequences:** This approach may lead to biased results if missing data are not missing completely at random (MCAR). If certain patterns of missingness are related to the outcome, the analysis may be biased.\n",
    "\n",
    "2. **Mean Imputation:**\n",
    "   - **Method:** Replace missing values with the mean of the observed values for that variable.\n",
    "   - **Consequences:** Mean imputation can distort the variability and relationships in the data. It assumes that missing values have the same mean as observed values, which may not be true.\n",
    "\n",
    "3. **Last Observation Carried Forward (LOCF):**\n",
    "   - **Method:** Replace missing values with the last observed value.\n",
    "   - **Consequences:** LOCF assumes that the last observed value is an accurate representation of the missing value. This may not be appropriate if the variable is changing over time.\n",
    "\n",
    "4. **Interpolation or Linear Imputation:**\n",
    "   - **Method:** Use linear interpolation between observed data points.\n",
    "   - **Consequences:** This method assumes a linear relationship between observed values, which may not be valid. It can be sensitive to the assumption of linearity.\n",
    "\n",
    "5. **Multiple Imputation:**\n",
    "   - **Method:** Generate multiple sets of imputed values for missing data, creating multiple datasets, and analyze each dataset separately.\n",
    "   - **Consequences:** Multiple imputation is a more sophisticated approach that accounts for uncertainty in imputed values. However, it requires assumptions about the distribution of missing data and may be computationally intensive.\n",
    "\n",
    "6. **Model-Based Imputation:**\n",
    "   - **Method:** Use a statistical model to impute missing values.\n",
    "   - **Consequences:** Model-based imputation considers the relationships within the data and can provide more accurate imputations. However, the validity of the model assumptions is crucial.\n",
    "\n",
    "The choice of method should be guided by the nature of the missing data and the assumptions that can reasonably be made. It's essential to report any method used for handling missing data in research publications and consider the potential impact on the validity of the results. Sensitivity analyses using different imputation methods can also be informative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3deed47",
   "metadata": {},
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d30581",
   "metadata": {},
   "source": [
    "In the context of Analysis of Variance (ANOVA), post-hoc tests are conducted to make pairwise comparisons between group means when the overall ANOVA indicates significant differences among groups. Here are some common post-hoc tests and when to use each one:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD) Test:**\n",
    "   - **Use Case:** Tukey's HSD is suitable when there are equal sample sizes in each group.\n",
    "   - **Example:** Suppose you conducted a one-way ANOVA comparing the test scores of students from three different teaching methods, and the ANOVA indicates a significant difference. You could use Tukey's HSD to identify which pairs of teaching methods have significantly different means.\n",
    "\n",
    "2. **Bonferroni Correction:**\n",
    "   - **Use Case:** Bonferroni correction is a conservative method appropriate when conducting multiple pairwise comparisons.\n",
    "   - **Example:** In a clinical trial with four treatment groups, you want to compare the mean effectiveness of each treatment with every other treatment. Since you are making multiple comparisons, you might use the Bonferroni correction to adjust the significance level for each comparison.\n",
    "\n",
    "3. **Scheffé's Test:**\n",
    "   - **Use Case:** Scheffé's test is more conservative and is suitable when sample sizes may be unequal.\n",
    "   - **Example:** In a study comparing the means of different age groups on a cognitive test, the ANOVA indicates a significant difference. Scheffé's test could be used for pairwise comparisons between age groups to identify where the significant differences lie.\n",
    "\n",
    "4. **Duncan's Multiple Range Test:**\n",
    "   - **Use Case:** Duncan's test is less conservative and is suitable when sample sizes are equal.\n",
    "   - **Example:** In an agricultural study comparing the yield of different fertilizers applied to crops, the ANOVA indicates a significant difference. Duncan's test can be used to compare the yields of individual fertilizers and identify significant differences.\n",
    "\n",
    "5. **Holm's Method:**\n",
    "   - **Use Case:** Holm's method is a step-down procedure that controls the familywise error rate.\n",
    "   - **Example:** In a marketing study comparing the sales performance of different advertising strategies, the ANOVA indicates a significant overall effect. Holm's method can be applied to make pairwise comparisons between specific advertising strategies while controlling for the overall error rate.\n",
    "\n",
    "When to use a particular post-hoc test depends on factors such as sample size, homogeneity of variances, and the desired level of control over the familywise error rate. It's essential to choose a test that aligns with the characteristics of the data and the study design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0605e",
   "metadata": {},
   "source": [
    "### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a490d9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 7.984872861507485\n",
      "P-Value: 0.0005104585600694623\n",
      "There is a significant difference between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate random weight loss data for each diet\n",
    "np.random.seed(42)  # for reproducibility\n",
    "weight_loss_A = np.random.normal(loc=5, scale=2, size=50)\n",
    "weight_loss_B = np.random.normal(loc=4.5, scale=1.5, size=50)\n",
    "weight_loss_C = np.random.normal(loc=6, scale=2.5, size=50)\n",
    "\n",
    "# Creating a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Diet': ['A']*50 + ['B']*50 + ['C']*50,\n",
    "    'WeightLoss': np.concatenate([weight_loss_A, weight_loss_B, weight_loss_C])\n",
    "})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(\n",
    "    data[data['Diet'] == 'A']['WeightLoss'],\n",
    "    data[data['Diet'] == 'B']['WeightLoss'],\n",
    "    data[data['Diet'] == 'C']['WeightLoss']\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e2fa7",
   "metadata": {},
   "source": [
    "### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1271d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   sum_sq    df         F    PR(>F)\n",
      "C(Program)                       1.334021   2.0  0.193670  0.824297\n",
      "C(ExperienceLevel)               5.096305   1.0  1.479736  0.227223\n",
      "C(Program):C(ExperienceLevel)    8.396750   2.0  1.219018  0.300694\n",
      "Residual                       289.301266  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# Create a DataFrame with columns: 'Program', 'ExperienceLevel', and 'CompletionTime'\n",
    "data = pd.DataFrame({\n",
    "    'Program': np.random.choice(['A', 'B', 'C'], size=90),\n",
    "    'ExperienceLevel': np.random.choice(['Novice', 'Experienced'], size=90),\n",
    "    'CompletionTime': np.random.normal(loc=10, scale=2, size=90)\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('CompletionTime ~ C(Program) + C(ExperienceLevel) + C(Program):C(ExperienceLevel)', data=data).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the results\n",
    "print(anova_table)\n",
    "\n",
    "# Interpret the results\n",
    "# Check the p-values for main effects and interaction effects\n",
    "# If p-value < 0.05, there is evidence of a significant effect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c7fc74",
   "metadata": {},
   "source": [
    "### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d909e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test:\n",
      "T-Statistic: -4.754695943505282\n",
      "P-Value: 3.819135262679469e-06\n",
      "\n",
      "Post-Hoc Test (Tukey's HSD):\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental   6.2615 0.001 3.6645 8.8585   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate random test scores for the control and experimental groups\n",
    "np.random.seed(42)  # for reproducibility\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Group': ['Control'] * 100 + ['Experimental'] * 100,\n",
    "    'TestScores': np.concatenate([control_scores, experimental_scores])\n",
    "})\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(\n",
    "    data[data['Group'] == 'Control']['TestScores'],\n",
    "    data[data['Group'] == 'Experimental']['TestScores']\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Two-Sample T-Test:\")\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Follow up with post-hoc test (Tukey's HSD)\n",
    "tukey_results = pairwise_tukeyhsd(data['TestScores'], data['Group'])\n",
    "\n",
    "# Print the post-hoc results\n",
    "print(\"\\nPost-Hoc Test (Tukey's HSD):\")\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc436477",
   "metadata": {},
   "source": [
    "### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "!pip install pingouin\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "# Generate random daily sales data for three stores over 30 days\n",
    "np.random.seed(42)  # for reproducibility\n",
    "days = 30\n",
    "sales_data = pd.DataFrame({\n",
    "    'Store_A': np.random.normal(loc=100, scale=10, size=days),\n",
    "    'Store_B': np.random.normal(loc=110, scale=15, size=days),\n",
    "    'Store_C': np.random.normal(loc=95, scale=12, size=days)\n",
    "})\n",
    "\n",
    "# Reshape the data for repeated measures ANOVA\n",
    "sales_long = pd.melt(sales_data, var_name='Store', value_name='DailySales')\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "rm_anova_result = pg.rm_anova(data=sales_long, dv='DailySales', within='Store')\n",
    "\n",
    "# Print the ANOVA result\n",
    "print(rm_anova_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
